[W socket.cpp:401] [c10d] The server socket cannot be initialized on [::]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:558] [c10d] The client socket cannot be initialized to connect to [localhost]:29500 (errno: 97 - Address family not supported by protocol).
[W socket.cpp:558] [c10d] The client socket cannot be initialized to connect to [localhost]:29500 (errno: 97 - Address family not supported by protocol).
[2022-06-16 04:03:42,099] [INFO] [distributed.py:48:init_distributed] Initializing torch distributed with backend: nccl
[2022-06-16 04:04:13,251] [INFO] [partition_parameters.py:463:__exit__] finished initializing model with 6.05B parameters
Using custom data configuration default-09a0c5a4c7e74dbb
Reusing dataset text (/home/vyomkeshj/.cache/huggingface/datasets/text/default-09a0c5a4c7e74dbb/0.0.0/08f6fb1dd2dab0a18ea441c359e1d63794ea8cb53e7863e6edf8fc5655e47ec4)
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 904.72it/s]
Using custom data configuration default-3cb01cf7977b9a02
Reusing dataset text (/home/vyomkeshj/.cache/huggingface/datasets/text/default-3cb01cf7977b9a02/0.0.0/08f6fb1dd2dab0a18ea441c359e1d63794ea8cb53e7863e6edf8fc5655e47ec4)
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1074.36it/s]
Using amp half precision backend
[2022-06-16 04:04:45,344] [INFO] [logging.py:69:log_dist] [Rank 0] DeepSpeed info: version=0.6.5, git-hash=unknown, git-branch=unknown
[2022-06-16 04:04:45,355] [INFO] [engine.py:278:__init__] DeepSpeed Flops Profiler Enabled: False
Using /home/vyomkeshj/.cache/torch_extensions/py310_cu111 as PyTorch extensions root...
Detected CUDA files, patching ldflags
Emitting ninja build file /home/vyomkeshj/.cache/torch_extensions/py310_cu111/cpu_adam/build.ninja...
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module cpu_adam...
Time to load cpu_adam op: 0.5347518920898438 seconds
Adam Optimizer #0 is created with AVX2 arithmetic capability.
Config: alpha=0.000050, betas=(0.900000, 0.999000), weight_decay=0.000000, adam_w=1
[2022-06-16 04:04:47,065] [INFO] [engine.py:1100:_configure_optimizer] Using DeepSpeed Optimizer param name adamw as basic optimizer
[2022-06-16 04:04:47,081] [INFO] [engine.py:1108:_configure_optimizer] DeepSpeed Basic Optimizer = DeepSpeedCPUAdam
[2022-06-16 04:04:47,081] [INFO] [utils.py:52:is_zero_supported_optimizer] Checking ZeRO support for optimizer=DeepSpeedCPUAdam type=<class 'deepspeed.ops.adam.cpu_adam.DeepSpeedCPUAdam'>
[2022-06-16 04:04:47,081] [INFO] [logging.py:69:log_dist] [Rank 0] Creating fp16 ZeRO stage 3 optimizer
[2022-06-16 04:04:47,081] [INFO] [engine.py:1410:_configure_zero_optimizer] Initializing ZeRO Stage 3
[2022-06-16 04:04:47,092] [INFO] [stage3.py:275:__init__] Reduce bucket size 500000000
[2022-06-16 04:04:47,092] [INFO] [stage3.py:276:__init__] Prefetch bucket size 50000000
Using /home/vyomkeshj/.cache/torch_extensions/py310_cu111 as PyTorch extensions root...
Emitting ninja build file /home/vyomkeshj/.cache/torch_extensions/py310_cu111/utils/build.ninja...
Building extension module utils...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module utils...
Time to load utils op: 0.0915982723236084 seconds
[2022-06-16 04:04:56,809] [INFO] [stage3.py:567:_setup_for_real_optimizer] optimizer state initialized
***** Running training *****
  Num examples = 6300
  Num Epochs = 3
  Instantaneous batch size per device = 16
  Total train batch size (w. parallel, distributed & accumulation) = 64
  Gradient Accumulation steps = 1
  Total optimization steps = 297
Automatic Weights & Biases logging enabled, to disable set os.environ["WANDB_DISABLED"] = "true"
  0%|                                                                                                                                      | 0/297 [00:00<?, ?it/s]
[2022-06-16 04:04:58,204] [INFO] [utils.py:828:see_memory_usage] After initializing ZeRO optimizer
[2022-06-16 04:04:58,205] [INFO] [utils.py:829:see_memory_usage] MA 1.04 GB         Max_MA 1.81 GB         CA 2.47 GB         Max_CA 2 GB
[2022-06-16 04:04:58,205] [INFO] [utils.py:837:see_memory_usage] CPU Virtual Memory:  used = 146.03 GB, percent = 78.0%
[2022-06-16 04:04:58,206] [INFO] [logging.py:69:log_dist] [Rank 0] DeepSpeed Final Optimizer = adamw
[2022-06-16 04:04:58,206] [INFO] [engine.py:785:_configure_lr_scheduler] DeepSpeed using configured LR scheduler = WarmupLR
[2022-06-16 04:04:58,206] [INFO] [logging.py:69:log_dist] [Rank 0] DeepSpeed LR Scheduler = <deepspeed.runtime.lr_schedules.WarmupLR object at 0x14eda438fc40>
[2022-06-16 04:04:58,206] [INFO] [logging.py:69:log_dist] [Rank 0] step=0, skipped=0, lr=[5e-05], mom=[[0.9, 0.999]]
[2022-06-16 04:04:58,207] [INFO] [config.py:1059:print] DeepSpeedEngine configuration:
[2022-06-16 04:04:58,207] [INFO] [config.py:1063:print]   activation_checkpointing_config  {
    "partition_activations": false,
    "contiguous_memory_optimization": false,
    "cpu_checkpointing": false,
    "number_checkpoints": null,
    "synchronize_checkpoint_boundary": false,
    "profile": false
}
[2022-06-16 04:04:58,207] [INFO] [config.py:1063:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2022-06-16 04:04:58,207] [INFO] [config.py:1063:print]   amp_enabled .................. False
[2022-06-16 04:04:58,207] [INFO] [config.py:1063:print]   amp_params ................... False
[2022-06-16 04:04:58,207] [INFO] [config.py:1063:print]   autotuning_config ............ {
    "enabled": false,
    "start_step": null,
    "end_step": null,
    "metric_path": null,
    "arg_mappings": null,
    "metric": "throughput",
    "model_info": null,
    "results_dir": null,
    "exps_dir": null,
    "overwrite": true,
    "fast": true,
    "start_profile_step": 3,
    "end_profile_step": 5,
    "tuner_type": "gridsearch",
    "tuner_early_stopping": 5,
    "tuner_num_trials": 50,
    "model_info_path": null,
    "mp_size": 1,
    "max_train_batch_size": null,
    "min_train_batch_size": 1,
    "max_train_micro_batch_size_per_gpu": 1.024000e+03,
    "min_train_micro_batch_size_per_gpu": 1,
    "num_tuning_micro_batch_sizes": 3
}
[2022-06-16 04:04:58,207] [INFO] [config.py:1063:print]   bfloat16_enabled ............. True
[2022-06-16 04:04:58,207] [INFO] [config.py:1063:print]   checkpoint_tag_validation_enabled  True
[2022-06-16 04:04:58,208] [INFO] [config.py:1063:print]   checkpoint_tag_validation_fail  False
[2022-06-16 04:04:58,208] [INFO] [config.py:1063:print]   communication_data_type ...... None
[2022-06-16 04:04:58,208] [INFO] [config.py:1063:print]   curriculum_enabled ........... False
[2022-06-16 04:04:58,208] [INFO] [config.py:1063:print]   curriculum_params ............ False
[2022-06-16 04:04:58,208] [INFO] [config.py:1063:print]   dataloader_drop_last ......... False
[2022-06-16 04:04:58,208] [INFO] [config.py:1063:print]   disable_allgather ............ False
[2022-06-16 04:04:58,208] [INFO] [config.py:1063:print]   dump_state ................... False
[2022-06-16 04:04:58,208] [INFO] [config.py:1063:print]   dynamic_loss_scale_args ...... None
[2022-06-16 04:04:58,208] [INFO] [config.py:1063:print]   eigenvalue_enabled ........... False
[2022-06-16 04:04:58,208] [INFO] [config.py:1063:print]   eigenvalue_gas_boundary_resolution  1
[2022-06-16 04:04:58,208] [INFO] [config.py:1063:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2022-06-16 04:04:58,208] [INFO] [config.py:1063:print]   eigenvalue_layer_num ......... 0
[2022-06-16 04:04:58,208] [INFO] [config.py:1063:print]   eigenvalue_max_iter .......... 100
[2022-06-16 04:04:58,208] [INFO] [config.py:1063:print]   eigenvalue_stability ......... 1e-06
[2022-06-16 04:04:58,208] [INFO] [config.py:1063:print]   eigenvalue_tol ............... 0.01
[2022-06-16 04:04:58,208] [INFO] [config.py:1063:print]   eigenvalue_verbose ........... False
[2022-06-16 04:04:58,208] [INFO] [config.py:1063:print]   elasticity_enabled ........... False
[2022-06-16 04:04:58,208] [INFO] [config.py:1063:print]   flops_profiler_config ........ {
    "enabled": false,
    "profile_step": 1,
    "module_depth": -1,
    "top_modules": 1,
    "detailed": true,
    "output_file": null
}
[2022-06-16 04:04:58,208] [INFO] [config.py:1063:print]   fp16_enabled ................. False
[2022-06-16 04:04:58,208] [INFO] [config.py:1063:print]   fp16_master_weights_and_gradients  False
[2022-06-16 04:04:58,208] [INFO] [config.py:1063:print]   fp16_mixed_quantize .......... False
[2022-06-16 04:04:58,208] [INFO] [config.py:1063:print]   global_rank .................. 0
[2022-06-16 04:04:58,208] [INFO] [config.py:1063:print]   gradient_accumulation_steps .. 1
[2022-06-16 04:04:58,208] [INFO] [config.py:1063:print]   gradient_clipping ............ 0.0
[2022-06-16 04:04:58,208] [INFO] [config.py:1063:print]   gradient_predivide_factor .... 1.0
[2022-06-16 04:04:58,208] [INFO] [config.py:1063:print]   initial_dynamic_scale ........ 1
[2022-06-16 04:04:58,208] [INFO] [config.py:1063:print]   loss_scale ................... 1.0
[2022-06-16 04:04:58,208] [INFO] [config.py:1063:print]   memory_breakdown ............. False
[2022-06-16 04:04:58,208] [INFO] [config.py:1063:print]   optimizer_legacy_fusion ...... False
[2022-06-16 04:04:58,209] [INFO] [config.py:1063:print]   optimizer_name ............... adamw
[2022-06-16 04:04:58,209] [INFO] [config.py:1063:print]   optimizer_params ............. {'lr': 5e-05, 'betas': [0.9, 0.999], 'eps': 1e-08}
[2022-06-16 04:04:58,209] [INFO] [config.py:1063:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}
[2022-06-16 04:04:58,209] [INFO] [config.py:1063:print]   pld_enabled .................. False
[2022-06-16 04:04:58,209] [INFO] [config.py:1063:print]   pld_params ................... False
[2022-06-16 04:04:58,209] [INFO] [config.py:1063:print]   prescale_gradients ........... False
[2022-06-16 04:04:58,209] [INFO] [config.py:1063:print]   quantize_change_rate ......... 0.001
[2022-06-16 04:04:58,209] [INFO] [config.py:1063:print]   quantize_groups .............. 1
[2022-06-16 04:04:58,209] [INFO] [config.py:1063:print]   quantize_offset .............. 1000
[2022-06-16 04:04:58,209] [INFO] [config.py:1063:print]   quantize_period .............. 1000
[2022-06-16 04:04:58,209] [INFO] [config.py:1063:print]   quantize_rounding ............ 0
[2022-06-16 04:04:58,209] [INFO] [config.py:1063:print]   quantize_start_bits .......... 16
[2022-06-16 04:04:58,209] [INFO] [config.py:1063:print]   quantize_target_bits ......... 8
[2022-06-16 04:04:58,209] [INFO] [config.py:1063:print]   quantize_training_enabled .... False
[2022-06-16 04:04:58,209] [INFO] [config.py:1063:print]   quantize_type ................ 0
[2022-06-16 04:04:58,209] [INFO] [config.py:1063:print]   quantize_verbose ............. False
[2022-06-16 04:04:58,209] [INFO] [config.py:1063:print]   scheduler_name ............... WarmupLR
[2022-06-16 04:04:58,209] [INFO] [config.py:1063:print]   scheduler_params ............. {'warmup_min_lr': 0, 'warmup_max_lr': 5e-05, 'warmup_num_steps': 100}
[2022-06-16 04:04:58,209] [INFO] [config.py:1063:print]   sparse_attention ............. None
[2022-06-16 04:04:58,209] [INFO] [config.py:1063:print]   sparse_gradients_enabled ..... False
[2022-06-16 04:04:58,209] [INFO] [config.py:1063:print]   steps_per_print .............. 10
[2022-06-16 04:04:58,209] [INFO] [config.py:1063:print]   tensorboard_enabled .......... False
[2022-06-16 04:04:58,209] [INFO] [config.py:1063:print]   tensorboard_job_name ......... DeepSpeedJobName
[2022-06-16 04:04:58,209] [INFO] [config.py:1063:print]   tensorboard_output_path ......
[2022-06-16 04:04:58,209] [INFO] [config.py:1063:print]   train_batch_size ............. 64
[2022-06-16 04:04:58,209] [INFO] [config.py:1063:print]   train_micro_batch_size_per_gpu  16
[2022-06-16 04:04:58,209] [INFO] [config.py:1063:print]   use_quantizer_kernel ......... False
[2022-06-16 04:04:58,209] [INFO] [config.py:1063:print]   wall_clock_breakdown ......... False
[2022-06-16 04:04:58,209] [INFO] [config.py:1063:print]   world_size ................... 4
[2022-06-16 04:04:58,210] [INFO] [config.py:1063:print]   zero_allow_untested_optimizer  False
[2022-06-16 04:04:58,210] [INFO] [config.py:1063:print]   zero_config .................. {
    "stage": 3,
    "contiguous_gradients": true,
    "reduce_scatter": true,
    "reduce_bucket_size": 5.000000e+08,
    "allgather_partitions": true,
    "allgather_bucket_size": 5.000000e+08,
    "overlap_comm": true,
    "load_from_fp32_weights": true,
    "elastic_checkpoint": false,
    "offload_param": {
        "device": "cpu",
        "nvme_path": null,
        "buffer_count": 5,
        "buffer_size": 1.000000e+08,
        "max_in_cpu": 1.000000e+09,
        "pin_memory": false
    },
    "offload_optimizer": {
        "device": "cpu",
        "nvme_path": null,
        "buffer_count": 4,
        "pin_memory": false,
        "pipeline_read": false,
        "pipeline_write": false,
        "fast_init": false,
        "pipeline": false
    },
    "sub_group_size": 1.000000e+09,
    "prefetch_bucket_size": 5.000000e+07,
    "param_persistence_threshold": 1.000000e+05,
    "max_live_parameters": 1.000000e+09,
    "max_reuse_distance": 1.000000e+09,
    "gather_16bit_weights_on_model_save": false,
    "ignore_unused_parameters": true,
    "round_robin_gradients": false,
    "legacy_stage1": false
}
[2022-06-16 04:04:58,210] [INFO] [config.py:1063:print]   zero_enabled ................. True
[2022-06-16 04:04:58,210] [INFO] [config.py:1063:print]   zero_optimization_stage ...... 3
[2022-06-16 04:04:58,210] [INFO] [config.py:1065:print]   json = {
    "train_batch_size": 64,
    "bf16": {
        "enabled": true,
        "min_loss_scale": 1,
        "opt_level": "O3"
    },
    "zero_optimization": {
        "stage": 3,
        "offload_param": {
            "device": "cpu"
        },
        "offload_optimizer": {
            "device": "cpu"
        },
        "allgather_partitions": true,
        "allgather_bucket_size": 5.000000e+08,
        "contiguous_gradients": true
    },
    "optimizer": {
        "type": "AdamW",
        "params": {
            "lr": 5e-05,
            "betas": [0.9, 0.999],
            "eps": 1e-08
        }
    },
    "scheduler": {
        "type": "WarmupLR",
        "params": {
            "warmup_min_lr": 0,
            "warmup_max_lr": 5e-05,
            "warmup_num_steps": 100
        }
    }
}
Using /home/vyomkeshj/.cache/torch_extensions/py310_cu111 as PyTorch extensions root...
No modifications detected for re-loaded extension module utils, skipping build step...
Loading extension module utils...
  0%|                                                                                                                                      | 0/297 [00:00<?, ?it/s]Traceback (most recent call last):
  File "/scratch/project/dd-21-23/test/gpt-neo-fine-tuning-example/./gpt_j_deepspeed.py", line 75, in <module>
    print("{}: {}".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)))
  File "/home/vyomkeshj/.conda/envs/ml_test/lib/python3.10/site-packages/transformers/trainer.py", line 1325, in train
    tr_loss_step = self.training_step(model, inputs)
  File "/home/vyomkeshj/.conda/envs/ml_test/lib/python3.10/site-packages/transformers/trainer.py", line 1884, in training_step
    loss = self.compute_loss(model, inputs)
  File "/home/vyomkeshj/.conda/envs/ml_test/lib/python3.10/site-packages/transformers/trainer.py", line 1916, in compute_loss
    outputs = model(**inputs)
  File "/home/vyomkeshj/.conda/envs/ml_test/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/vyomkeshj/.conda/envs/ml_test/lib/python3.10/site-packages/deepspeed/utils/nvtx.py", line 11, in wrapped_fn
    return func(*args, **kwargs)
  File "/home/vyomkeshj/.conda/envs/ml_test/lib/python3.10/site-packages/deepspeed/runtime/engine.py", line 1616, in forward
    loss = self.module(*inputs, **kwargs)
  File "/home/vyomkeshj/.conda/envs/ml_test/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1128, in _call_impl
    result = forward_call(*input, **kwargs)
  File "/home/vyomkeshj/.conda/envs/ml_test/lib/python3.10/site-packages/transformers/models/gptj/modeling_gptj.py", line 782, in forward
    transformer_outputs = self.transformer(
  File "/home/vyomkeshj/.conda/envs/ml_test/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1128, in _call_impl
    result = forward_call(*input, **kwargs)
  File "/home/vyomkeshj/.conda/envs/ml_test/lib/python3.10/site-packages/transformers/models/gptj/modeling_gptj.py", line 636, in forward
    outputs = block(
  File "/home/vyomkeshj/.conda/envs/ml_test/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1128, in _call_impl
    result = forward_call(*input, **kwargs)
  File "/home/vyomkeshj/.conda/envs/ml_test/lib/python3.10/site-packages/transformers/models/gptj/modeling_gptj.py", line 291, in forward
    feed_forward_hidden_states = self.mlp(hidden_states)
  File "/home/vyomkeshj/.conda/envs/ml_test/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1128, in _call_impl
    result = forward_call(*input, **kwargs)
  File "/home/vyomkeshj/.conda/envs/ml_test/lib/python3.10/site-packages/transformers/models/gptj/modeling_gptj.py", line 256, in forward
    hidden_states = self.fc_out(hidden_states)
  File "/home/vyomkeshj/.conda/envs/ml_test/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1117, in _call_impl
    result = hook(self, input)
  File "/home/vyomkeshj/.conda/envs/ml_test/lib/python3.10/site-packages/deepspeed/utils/nvtx.py", line 11, in wrapped_fn
    return func(*args, **kwargs)
  File "/home/vyomkeshj/.conda/envs/ml_test/lib/python3.10/site-packages/deepspeed/runtime/zero/stage3.py", line 1130, in _pre_forward_module_hook
    self.pre_sub_module_forward_function(module)
  File "/home/vyomkeshj/.conda/envs/ml_test/lib/python3.10/site-packages/torch/autograd/grad_mode.py", line 27, in decorate_context
    return func(*args, **kwargs)
  File "/home/vyomkeshj/.conda/envs/ml_test/lib/python3.10/site-packages/deepspeed/runtime/zero/stage3.py", line 1253, in pre_sub_module_forward_function
    param_coordinator.fetch_sub_module(sub_module)
  File "/home/vyomkeshj/.conda/envs/ml_test/lib/python3.10/site-packages/deepspeed/utils/nvtx.py", line 11, in wrapped_fn
    return func(*args, **kwargs)
  File "/home/vyomkeshj/.conda/envs/ml_test/lib/python3.10/site-packages/torch/autograd/grad_mode.py", line 27, in decorate_context
    return func(*args, **kwargs)
  File "/home/vyomkeshj/.conda/envs/ml_test/lib/python3.10/site-packages/deepspeed/runtime/zero/partitioned_param_coordinator.py", line 258, in fetch_sub_module
    self.__all_gather_params(params_to_fetch)
  File "/home/vyomkeshj/.conda/envs/ml_test/lib/python3.10/site-packages/deepspeed/utils/nvtx.py", line 11, in wrapped_fn
    return func(*args, **kwargs)
  File "/home/vyomkeshj/.conda/envs/ml_test/lib/python3.10/site-packages/deepspeed/runtime/zero/partitioned_param_coordinator.py", line 399, in __all_gather_params
    handle = partitioned_params[0].all_gather_coalesced(partitioned_params)
  File "/home/vyomkeshj/.conda/envs/ml_test/lib/python3.10/site-packages/deepspeed/utils/nvtx.py", line 11, in wrapped_fn
    return func(*args, **kwargs)
  File "/home/vyomkeshj/.conda/envs/ml_test/lib/python3.10/site-packages/deepspeed/runtime/zero/partition_parameters.py", line 886, in all_gather_coalesced
    [p.ds_tensor.to(torch.cuda.current_device()) for p in params],
  File "/home/vyomkeshj/.conda/envs/ml_test/lib/python3.10/site-packages/deepspeed/runtime/zero/partition_parameters.py", line 886, in <listcomp>
    [p.ds_tensor.to(torch.cuda.current_device()) for p in params],
RuntimeError: CUDA out of memory. Tried to allocate 32.00 MiB (GPU 0; 15.78 GiB total capacity; 14.22 GiB already allocated; 20.19 MiB free; 14.26 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF